# Kubeflow

Kubeflow is a Machine Learning toolkit for creating pipelines on kubeernetes. It makes it easy pipe data from one step to another. Kubeflow v2 pipelines can also be used on the google cloud platform using the Vertex AI service. In this section we will install kubeflow on a kubernetes cluster on the GCP. Aftwerwards we will use the kubeflow pipelines to create a pipeline that trains a model on the Vertex AI. As an example of a pipeline we will create a pipeline for training InterfaceGan boundaries for the StyleGAN3 model

## Prerequisites

### Install Conda

Install conda for your platform. See [here](https://docs.conda.io/projects/conda/en/latest/user-guide/install/index.html).

```bash
 conda create -n adv-mlops python=3.9
```

```bash
 conda activate adv-mlops
```

### Run steps

We will first install kubeflow on the create K8 cluster in GCP.

1 Run

1 Run `2.0_create_bucket.sh` to create a bucket for the pipeline data.

## Kubeflow Pipelines

Kubeflow pipelines are a way to orchestrate the execution of multiple containers in a Kubeflow cluster. The containers can be written in any language and can be used to perform any task. The containers can be chained together to form a pipeline. Kubeflow can automatically pipe output data to the next pipeline component. This allows for the creation of complex pipelines that can be run on a Kubeflow cluster. Vertex AI, googles ai platform, also supports Kubeflow pipelines.

### Kubeflow Component

There is different ways to define a kubeflow component. You can either created directly in python, by defining a function [1](https://www.kubeflow.org/docs/components/pipelines/v1/sdk-v2/python-function-components/), or by defining a container [2](https://www.kubeflow.org/docs/components/pipelines/v1/sdk-v2/component-development/). In this project we will use the second approach. This allows us to easy use existing code and docker images.

### Train boundary interfaceGAN

This pipeline trains a interfaceGAN boundary for StyleGAN3. The pipeline consists of the following steps:
1 Sampler - generate N number of faces usinge the GAN model
2 Classifier - classify the faces generated by the GAN model using the classifier model
3 Supported Vector Machine - find boundary for the classifier model in the latent space

## References

[Guide to run kubeflow] [https://codelabs.developers.google.com/codelabs/cloud-kubeflow-pipelines-gis/index.html?index=..%2F..index#2](https://codelabs.developers.google.com/codelabs/cloud-kubeflow-pipelines-gis/index.html?index=..%2F..index#2)
